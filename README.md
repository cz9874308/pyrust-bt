# pyrust-bt

<div  align="center">
<img src="images/logo.jpeg" width = "200" height = "200" alt="" align=center />
</div>

A hybrid backtesting framework: Python for strategy and data, Rust for the high-performance core via PyO3 bindings. Designed to balance researcher productivity with engine throughput, suitable from research to small-team production.

[ä¸­æ–‡æ–‡æ¡£ | Chinese README](README.zh-CN.md)

## Features

-   Rust Engine

    -   Time advancement over bars/ticks
    -   Order matching: market/limit (same-bar simplified execution)
    -   Cost model: commission `commission_rate`, slippage `slippage_bps`
    -   Portfolio & ledger: `position / avg_cost / cash / equity / realized_pnl`
    -   Vectorized indicators: `SMA / RSI` (sliding window optimized)
    -   Statistics: total return, annualized return, volatility, Sharpe, Calmar, max drawdown & duration
    -   Performance: batch processing (`batch_size`), pre-extracted data, preallocated buffers, inlined hot paths

-   Python API

    -   Strategy lifecycle: `on_start` â†’ `next(bar)` â†’ `on_stop` with `on_order / on_trade` callbacks
    -   Action format:
        -   String: `"BUY" | "SELL"`
        -   Dict: `{ "action": "BUY"|"SELL", "type": "market"|"limit", "size": float, "price"?: float }`
    -   Data loader: CSV â†’ list[dict] (MVP; pluggable for Parquet/Arrow)
    -   Analyzers: drawdown segments, round-trips, enhanced performance metrics, factor backtests (quantiles/IC/monotonicity), unified report
    -   **Cross-sectional Factor Analysis**: multi-factor evaluation system, quantile portfolio backtesting, IC/ICIR analysis, factor ranking
    -   Optimizer: naive grid search (customizable scoring key)

-   API & Frontend
    -   FastAPI: `POST /runs`, `GET /runs`, `GET /runs/{id}`
    -   Streamlit: submit runs, list & visualize results (equity curve + stats)

## Install & Build

Prereqs: Python 3.8+, Rust (`rustup`), maturin

```powershell
pip install maturin
cd rust/engine_rust

# Option A: Install directly into the active Python environment (best for local dev)
maturin develop --release

# Option B: Build wheel only, install manually afterwards
python -m maturin build --release
pip install --force-reinstall (Get-ChildItem target/wheels/engine_rust-*.whl | Select-Object -First 1).FullName
```

## Quick Start

-   Minimal backtest

    ```powershell
    cd ../..
    python examples/run_mvp.py
    ```

-   Analyzer demo

    ```powershell
    python examples/run_analyzers.py
    ```

-   Grid search

    ```powershell
    python examples/run_grid_search.py
    ```

-   Cross-sectional factor backtesting

    ```powershell
    python examples/run_cs_momentum_sample.py
    ```

-   Quantile portfolio backtesting with trading simulation

    ```powershell
    python examples/run_cs_quantile_portfolios.py
    ```

-   Performance test & batch-size comparison

    ```powershell
    python examples/run_performance_test.py
    ```

Sample data: `examples/data/sample.csv` (headers: `datetime,open,high,low,close,volume`).

## Market Data: DuckDB + QMT

### DuckDB Local Store

-   The default database lives at `data/backtest.db`, but you can point scripts to any DuckDB file via `--db`.
-   Bulk-import historical data:

    ```powershell
    # Write CSV directly into DuckDB (requires the compiled engine_rust extension)
    python examples/import_csv_to_db.py data/513500_d.csv --symbol 513500.SH --period 1d --db data/backtest.db
    ```

-   Use `--no-direct-csv` to parse the CSV in Python first (useful for inspection) before saving through Rust.
-   Internally `save_klines` / `save_klines_from_csv` persist to the canonical schema; feel free to inspect the DB with `duckdb` CLI or any DuckDB-compatible tool.

### Zero-Maintenance QMT / XtData Backfill

-   When the local DuckDB store misses date ranges, `MarketDataService` can call QMT Mini (xtdata) to download the gap and write it back, achieving a â€œDB first â†’ auto backfillâ€ workflow.
-   Preparation checklist:
    1. Install the `XtQuant` Python package by copying it into your interpreterâ€™s `site-packages`, e.g. `D:\ProgramData\miniconda3\Lib\site-packages` (adjust to your environment).
    2. Verify `import XtQuant.XtData` works in Python.
    3. Set the `XTDATA_DIR` environment variable to the MiniQmt `userdata_mini` directory (default in examples: `D:\å›½é‡‘è¯åˆ¸QMTäº¤æ˜“ç«¯\userdata_mini`).
-   Run the multi-asset equal-weight example to smoke-test the data pipeline:

    ```powershell
    python examples/run_multi_asset_rebalance_strategy.py
    ```

-   See `docs/xtdata_market_data_plan.md` for architecture details and operational recommendations.

## In Code

-   Config & engine

    ```python
    from pyrust_bt.api import BacktestEngine, BacktestConfig
    cfg = BacktestConfig(start="2020-01-01", end="2020-12-31", cash=100000,
                         commission_rate=0.0005, slippage_bps=2.0, batch_size=1000)
    engine = BacktestEngine(cfg)
    ```

-   Strategy (minimal)

    ```python
    from pyrust_bt.strategy import Strategy
    class MyStrategy(Strategy):
        def next(self, bar):
            if bar["close"] > 100:
                return {"action": "BUY", "type": "market", "size": 1.0}
            return None
    ```

-   Run

    ```python
    from pyrust_bt.data import load_csv_to_bars
    bars = load_csv_to_bars("examples/data/sample.csv", symbol="SAMPLE")
    result = engine.run(MyStrategy(), bars)
    print(result["stats"], result["equity"])  # stats & equity
    ```

## Analysis & Reports

-   Drawdown segments: `compute_drawdown_segments(equity_curve)`
-   Round trips: `round_trips_from_trades(trades, bars)` / export CSV
-   Performance metrics: `compute_performance_metrics(equity_curve)` (Sharpe/Sortino/Calmar/VAR)
-   Factor backtest: `factor_backtest(bars, factor_key, quantiles, forward)`
-   Unified report: `generate_analysis_report(...)`
-   **Cross-sectional Factor Evaluation**:
    -   Multi-factor analyzer: `MultiFactorAnalyzer` with time-series/cross-sectional methods
    -   Factor ranking: IC, ICIR, monotonicity, stability, turnover analysis
    -   Quantile portfolio backtesting: `CrossSectionFactorBacktester` for large-scale factor evaluation
    -   Export: detailed reports, factor rankings, correlation matrices

## API & Frontend

-   Start API (FastAPI)

    ```powershell
    pip install fastapi uvicorn pydantic requests streamlit
    python -m uvicorn python.server_main:app --reload
    ```

-   Start frontend (Streamlit)

    ```powershell
    set PYRUST_BT_API=http://127.0.0.1:8000
    streamlit run frontend/streamlit_app.py
    ```

## Performance Notes

-   Prefer larger `batch_size` (e.g., 1000â€“5000) to reduce Python round-trips
-   Prefer dict actions over strings
-   Use Rust vectorized indicators (`compute_sma/compute_rsi`) when possible
-   For large data, prefer Parquet/Arrow and partitioned reads (by symbol/time)

## Architecture

### System Architecture

The following diagram illustrates the overall architecture of pyrust-bt:

```mermaid
graph TB
    subgraph "Frontend Layer"
        UI[Streamlit UI<br/>å¯è§†åŒ–ç•Œé¢]
    end

    subgraph "API Layer"
        API[FastAPI Server<br/>RESTful API]
    end

    subgraph "Python Application Layer"
        Strategy[Strategy<br/>ç­–ç•¥å®šä¹‰]
        Wrapper[API Wrapper<br/>Pythonæ¥å£å°è£…]
        DataLoader[Data Loader<br/>æ•°æ®åŠ è½½å™¨]
        Analyzers[Analyzers<br/>æ€§èƒ½åˆ†æå™¨]
        MarketData[Market Data Service<br/>å¸‚åœºæ•°æ®æœåŠ¡]
    end

    subgraph "Rust Engine Layer (PyO3)"
        Engine[BacktestEngine<br/>å›æµ‹å¼•æ“æ ¸å¿ƒ]
        Config[BacktestConfig<br/>å›æµ‹é…ç½®]
        Context[EngineContext<br/>æ‰§è¡Œä¸Šä¸‹æ–‡]
        Indicators[Vectorized Indicators<br/>å‘é‡åŒ–æŒ‡æ ‡è®¡ç®—]
        Stats[Statistics<br/>ç»Ÿè®¡è®¡ç®—]
        DBModule[Database Module<br/>æ•°æ®åº“æ“ä½œæ¨¡å—]
    end

    subgraph "Data Storage Layer"
        DuckDB[(DuckDB<br/>Kçº¿æ•°æ®å­˜å‚¨)]
        CSV[CSV Files<br/>CSVæ•°æ®æ–‡ä»¶]
    end

    UI -->|HTTP Request| API
    API -->|è°ƒç”¨| Wrapper
    Wrapper -->|PyO3ç»‘å®š| Engine
    Strategy -->|ç­–ç•¥é€»è¾‘| Engine
    DataLoader -->|åŠ è½½æ•°æ®| Wrapper
    MarketData -->|æŸ¥è¯¢æ•°æ®| DuckDB
    Engine -->|è¯»å–æ•°æ®| DuckDB
    Engine -->|ä¿å­˜æ•°æ®| DuckDB
    CSV -->|å¯¼å…¥| DuckDB
    Engine -->|è¿”å›ç»“æœ| Analyzers
    Analyzers -->|åˆ†ææŠ¥å‘Š| API
    API -->|JSONå“åº”| UI
    Engine -->|ä½¿ç”¨| Config
    Engine -->|æä¾›| Context
    Engine -->|è°ƒç”¨| Indicators
    Engine -->|è°ƒç”¨| Stats
    Engine -->|ä½¿ç”¨| DBModule
```

### Data Flow

The following diagram shows the complete data flow from input to output:

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·/å‰ç«¯
    participant API as FastAPI
    participant Python as Python Layer
    participant Rust as Rust Engine
    participant DB as DuckDB
    participant CSV as CSV Files

    Note over User,CSV: æ•°æ®å‡†å¤‡é˜¶æ®µ
    User->>CSV: æä¾›CSVæ•°æ®æ–‡ä»¶
    CSV->>Python: è¯»å–CSVæ–‡ä»¶
    Python->>DB: å¯¼å…¥æ•°æ®åˆ°DuckDB<br/>(save_klines_from_csv)
    DB-->>Python: æ•°æ®ä¿å­˜æˆåŠŸ

    Note over User,CSV: å›æµ‹æ‰§è¡Œé˜¶æ®µ
    User->>API: POST /runs (æäº¤å›æµ‹ä»»åŠ¡)
    API->>Python: åˆ›å»ºBacktestEngine
    Python->>Rust: åˆå§‹åŒ–å¼•æ“(PyO3)
    Rust-->>Python: å¼•æ“å°±ç»ª

    Python->>DB: æŸ¥è¯¢Kçº¿æ•°æ®<br/>(get_market_data)
    DB-->>Python: è¿”å›Kçº¿åˆ—è¡¨
    Python->>Rust: é¢„æå–æ•°æ®åˆ°Rustç»“æ„<br/>(extract_bars_data)
    Rust-->>Python: æ•°æ®å‡†å¤‡å®Œæˆ

    loop æ¯æ ¹Kçº¿å¤„ç†
        Rust->>Python: è°ƒç”¨ç­–ç•¥next()æ–¹æ³•<br/>(ä¼ å…¥barå’Œcontext)
        Python->>Python: ç­–ç•¥é€»è¾‘è®¡ç®—
        Python-->>Rust: è¿”å›äº¤æ˜“ä¿¡å·<br/>(BUY/SELL/None)
        Rust->>Rust: è®¢å•æ’®åˆ<br/>(å¸‚ä»·/é™ä»·)
        Rust->>Rust: æ›´æ–°æŒä»“çŠ¶æ€<br/>(position/cash/equity)
        Rust->>Python: è§¦å‘å›è°ƒ<br/>(on_order/on_trade)
        Rust->>Rust: è®°å½•å‡€å€¼æ›²çº¿
    end

    Rust->>Rust: è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡<br/>(æ”¶ç›Š/å¤æ™®/å›æ’¤ç­‰)
    Rust-->>Python: è¿”å›å›æµ‹ç»“æœ
    Python->>Python: æ€§èƒ½åˆ†æ<br/>(Analyzers)
    Python-->>API: è¿”å›å®Œæ•´ç»“æœ
    API-->>User: JSONå“åº”<br/>(stats/equity/trades)

    Note over User,CSV: ç»“æœå±•ç¤ºé˜¶æ®µ
    User->>API: GET /runs/{id}
    API-->>User: è¿”å›å›æµ‹ç»“æœ
    User->>User: å¯è§†åŒ–å±•ç¤º<br/>(å‡€å€¼æ›²çº¿/ç»Ÿè®¡æŒ‡æ ‡)
```

### Key Components

-   **Frontend Layer**: Streamlit-based web UI for submitting backtests and visualizing results
-   **API Layer**: FastAPI RESTful API for managing backtest runs
-   **Python Layer**: Strategy definitions, data loading, analysis tools, and API wrappers
-   **Rust Engine**: High-performance core engine with PyO3 bindings for order matching, position management, and statistics
-   **Data Storage**: DuckDB for efficient K-line data storage and retrieval

### Performance Optimization Points

1. **Data Pre-extraction**: All bar data is extracted to Rust structures upfront, reducing Pythonâ†”Rust round-trips
2. **Batch Processing**: Configurable `batch_size` to reduce GIL contention when calling Python strategies
3. **Vectorized Operations**: Optimized indicator calculations using sliding window algorithms
4. **Direct Database Access**: Rust functions directly query DuckDB, bypassing Python overhead
5. **Temporary Table Strategy**: Ultra-fast batch inserts using temporary tables for data persistence

## Project Structure

-   `rust/engine_rust`: Rust engine (PyO3), indicators & stats
-   `python/pyrust_bt`: Python API/strategy/data/analyzers/optimizer
-   `python/pyrust_bt/multi_factor_analyzer.py`: Multi-factor evaluation system
-   `python/pyrust_bt/cs_factor_backtester.py`: Cross-sectional factor backtesting
-   `examples`: MVP, analyzers, grid search, performance tests
-   `examples/run_cs_momentum_sample.py`: Cross-sectional momentum factor demo
-   `examples/run_cs_quantile_portfolios.py`: Quantile portfolio trading simulation
-   `frontend`: Streamlit UI

## TODO / Roadmap

-   Engine/Matching
    -   Partial fills, order book, stop/take-profit, OCO, conditional orders
    -   Multi-asset/multi-timeframe alignment, calendar/timezone
    -   Liquidity/impact models
-   Data
    -   Parquet/Arrow zero-copy pipelines, columnar batching
    -   DataFeed abstraction (DB/object storage) & caching
-   Analysis/Reports
    -   Rich analyzers (group stats, drawdown visualization, trade distributions)
    -   Report export (PDF/HTML) & multi-run comparison
    -   Advanced factor analysis (industry/market cap neutralization, rolling quantiles)
-   Optimization/Parallelism
    -   Random/Bayesian search, cross-validation
    -   Multi-process/distributed runs (Ray/Celery/k8s Jobs)
-   Frontend/UX
    -   React + ECharts/Plotly (task mgmt, playback, filters, annotations)
    -   WebSocket live logs/progress/equity
-   Quality/Eng
    -   Unit/integration/regression tests, benchmarks
    -   CI (wheel build/artifacts), releases

## ğŸš€ Performance Highlights

-   Backtest speed: from 1,682 bars/s to **419,552 bars/s** (â‰ˆ250Ã—)
-   Dataset: 550k bars in ~1.3s
-   Memory: preallocated buffers to reduce reallocations
-   Batching: configurable `batch_size` to reduce GIL contention

## Community

Pull requests are welcome!

![Join](images/yzbjs1.png)

## License

MIT

## Disclaimer

This tool is for research and education only and does not constitute investment advice. You are solely responsible for your trading decisions and associated risks.
